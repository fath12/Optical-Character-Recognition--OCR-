{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MMOCR Training\n",
        "\n",
        "This notebook contains all source code to train text detection and recognition models. You don't need to change anything except the path to datasets and config file modification."
      ],
      "metadata": {
        "id": "unQLhztUxTeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cX-e7e2En6po",
        "outputId": "e1214cab-98aa-4e31-db22-6809831f7165"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Preparation\n",
        "\n",
        "First, we need to change the format of the Label Studio annotation to MMOCR annotation."
      ],
      "metadata": {
        "id": "ERHB8JGHFasq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset to local directory. Change in to your case."
      ],
      "metadata": {
        "id": "SyvHe-ewxWyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/Data PC/Data/Dibimbing/Day 25/Assignment/handwriting\" \"./handwriting\""
      ],
      "metadata": {
        "id": "Ubn2Wue3FGFD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple"
      ],
      "metadata": {
        "id": "h7_PvZRF6n67"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions for text detection dataset preparation"
      ],
      "metadata": {
        "id": "bYVJgiyFxzvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xywh2xyxy(xywh: List[float], img_width: int, img_height: int) -> List[int]:\n",
        "    \"\"\"\n",
        "    Change bounding box format xywh normalized to xyxy\n",
        "    \"\"\"\n",
        "    x, y, w, h = xywh\n",
        "    x = x * img_width / 100\n",
        "    y = y * img_height / 100\n",
        "    w = w * img_width / 100\n",
        "    h = h * img_height / 100\n",
        "    return [\n",
        "        int(x),\n",
        "        int(y),\n",
        "        int(x + w),\n",
        "        int(y + h),\n",
        "    ]\n",
        "\n",
        "def xyxy2poly(xyxy: List[int]) -> List[int]:\n",
        "    \"\"\"\n",
        "    Change bounding box format from xyxy to polygon\n",
        "    format xyxyxy...\n",
        "    \"\"\"\n",
        "    x1, y1, x2, y2 = xyxy\n",
        "    return [\n",
        "        x1, y1, x1, y2, x2, y2, x2, y1\n",
        "    ]\n",
        "\n",
        "\n",
        "def create_instance_mmocr_anno(\n",
        "    label_ls: Dict,\n",
        "    text: str,\n",
        "    img_width: int,\n",
        "    img_height: int,\n",
        ") -> Dict:\n",
        "    \"\"\"\n",
        "    Conver annotation of a text instance from label studio format\n",
        "    to MMOCR format\n",
        "    \"\"\"\n",
        "    bbox = xywh2xyxy(\n",
        "        [\n",
        "            label_ls[\"x\"],\n",
        "            label_ls[\"y\"],\n",
        "            label_ls[\"width\"],\n",
        "            label_ls[\"height\"],\n",
        "        ],\n",
        "        img_width,\n",
        "        img_height,\n",
        "    )\n",
        "    instance_anno = {}\n",
        "    instance_anno[\"bbox\"] = bbox\n",
        "    instance_anno[\"bbox_label\"] = 0\n",
        "    instance_anno[\"polygon\"] = xyxy2poly(bbox)\n",
        "    instance_anno[\"text\"] = text\n",
        "    instance_anno[\"ignore\"] = False\n",
        "    return instance_anno\n",
        "\n",
        "def create_image_mmocr_anno(image_name: str, image_ls: Dict) -> Dict:\n",
        "    \"\"\"\n",
        "    Conver annotation of an image from label studio format\n",
        "    to MMOCR format\n",
        "    \"\"\"\n",
        "    img_width = image_ls[\"label\"][0][\"original_width\"]\n",
        "    img_height = image_ls[\"label\"][0][\"original_height\"]\n",
        "    image_anno = {}\n",
        "    image_anno[\"img_path\"] = image_name\n",
        "    image_anno[\"height\"] = img_height\n",
        "    image_anno[\"width\"] = img_width\n",
        "    image_anno[\"instances\"] = [\n",
        "        create_instance_mmocr_anno(lbl, txt, img_width, img_height)\n",
        "        for lbl, txt in zip(image_ls[\"label\"], image_ls[\"transcription\"])\n",
        "    ]\n",
        "    return image_anno\n",
        "\n",
        "def create_metainfo_det() -> Dict:\n",
        "    \"\"\"\n",
        "    Metainfo for MMOCR text detection dataset\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"dataset_type\": \"TextDetDataset\",\n",
        "        \"task_name\": \"textdet\",\n",
        "        \"category\": [{\"id\": 0, \"name\": \"text\"}],\n",
        "    }\n",
        "\n",
        "def create_output_json(\n",
        "    annotations: List[Dict],\n",
        "    metainfo: Dict,\n",
        "    output_path: Path\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Dump MMOCR annotation JSON\n",
        "    \"\"\"\n",
        "    output = {\n",
        "        \"metainfo\": metainfo,\n",
        "        \"data_list\": annotations\n",
        "    }\n",
        "    with open(output_path, \"w\") as f:\n",
        "        json.dump(output, f)\n",
        "\n",
        "def get_image_name(ls_image_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Label studio will write the image file name in format of\n",
        "    '{random_id}-{original_image_name}'. So we only want to\n",
        "    get the original image name, since that is the name that\n",
        "    we have.\n",
        "    \"\"\"\n",
        "    name = os.path.basename(ls_image_path)\n",
        "    name = name[(name.find(\"-\") + 1):]\n",
        "    return name\n",
        "\n",
        "def create_mmocr_det_anno(\n",
        "    ls_anno_path: Path,\n",
        "    train_images_dir: Path,\n",
        "    test_images_dir: Path,\n",
        "    output_dir: Path,\n",
        "):\n",
        "    \"\"\"\n",
        "    Create text detection dataset in MMOCR format\n",
        "    \"\"\"\n",
        "    train_images = [p for p in train_images_dir.glob(\"*\")]\n",
        "    test_images = [p for p in test_images_dir.glob(\"*\")]\n",
        "    with open(ls_anno_path, \"r\") as f:\n",
        "        ls_anno = json.load(f)\n",
        "    image_annos = {}\n",
        "    for ann in ls_anno:\n",
        "        img_name = get_image_name(ann[\"ocr\"])\n",
        "        image_annos[img_name] = create_image_mmocr_anno(img_name, ann)\n",
        "\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    for p in [*train_images, *test_images]:\n",
        "      shutil.copy(p, output_dir / p.name)\n",
        "    create_output_json(\n",
        "        annotations=[image_annos[p.name] for p in train_images],\n",
        "        metainfo=create_metainfo_det(),\n",
        "        output_path=output_dir / \"textdet_train.json\"\n",
        "    )\n",
        "    create_output_json(\n",
        "        annotations=[image_annos[p.name] for p in test_images],\n",
        "        metainfo=create_metainfo_det(),\n",
        "        output_path=output_dir / \"textdet_test.json\"\n",
        "    )"
      ],
      "metadata": {
        "id": "Bd8rEfNYUCX9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions for text recognition dataset preparation"
      ],
      "metadata": {
        "id": "RaTA3CZxx4vF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_metainfo_rec() -> Dict:\n",
        "    \"\"\"\n",
        "    Metainfo for MMOCR text recognition dataset\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"dataset_type\": \"TextRecogDataset\",\n",
        "        \"task_name\": \"textrecog\",\n",
        "    }\n",
        "\n",
        "def crop_images(\n",
        "    src_annos: Dict,\n",
        "    image_src_dir: Path,\n",
        "    image_dst_dir: Path,\n",
        ") -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Crop text images and extract the text annotations\n",
        "    \"\"\"\n",
        "    image_path = image_src_dir / src_annos[\"img_path\"]\n",
        "    image = cv2.imread(str(image_path))\n",
        "    image_name = image_path.stem\n",
        "\n",
        "    anns = []\n",
        "    for i, src_txt_anno in enumerate(src_annos[\"instances\"]):\n",
        "        dst_image_file = f\"{image_name}_{i:05}.jpg\"\n",
        "        x1, y1, x2, y2 = src_txt_anno[\"bbox\"]\n",
        "        crop = image[y1:y2, x1:x2]\n",
        "        cv2.imwrite(str(image_dst_dir / dst_image_file), crop)\n",
        "\n",
        "        instance = [{\"text\": src_txt_anno[\"text\"]}]\n",
        "        crop_ann = {\n",
        "            \"img_path\": dst_image_file,\n",
        "            \"height\": crop.shape[0],\n",
        "            \"width\": crop.shape[1],\n",
        "            \"instances\": instance\n",
        "        }\n",
        "        anns.append(crop_ann)\n",
        "    return anns\n",
        "\n",
        "\n",
        "def create_split_anno(\n",
        "    det_anno_path: Path,\n",
        "    det_images_dir: Path,\n",
        "    output_dir: Path,\n",
        "    json_name: str,\n",
        "):\n",
        "    \"\"\"\n",
        "    Create formatted text recognition dataset for\n",
        "    a dataset split.\n",
        "    \"\"\"\n",
        "    with open(det_anno_path, \"r\") as f:\n",
        "        det_anno = json.load(f)\n",
        "    new_data_list = []\n",
        "    for src_anno in det_anno[\"data_list\"]:\n",
        "        new_data_list += crop_images(\n",
        "            src_anno,\n",
        "            det_images_dir,\n",
        "            output_dir,\n",
        "        )\n",
        "    new_anno = {\n",
        "        \"metainfo\": create_metainfo_rec(),\n",
        "        \"data_list\": new_data_list,\n",
        "    }\n",
        "    with open(output_dir / json_name, \"w\") as f:\n",
        "      json.dump(new_anno, f)\n",
        "\n",
        "def create_mmocr_rec_anno(\n",
        "    det_root_dir: Path,\n",
        "    output_dir: Path,\n",
        "):\n",
        "    \"\"\"\n",
        "    Create text recognition dataset in MMOCR format\n",
        "    \"\"\"\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    create_split_anno(\n",
        "        det_root_dir / \"textdet_train.json\",\n",
        "        det_root_dir,\n",
        "        output_dir,\n",
        "        \"textrecog_train.json\"\n",
        "    )\n",
        "    create_split_anno(\n",
        "        det_root_dir / \"textdet_test.json\",\n",
        "        det_root_dir,\n",
        "        output_dir,\n",
        "        \"textrecog_test.json\"\n",
        "    )"
      ],
      "metadata": {
        "id": "UuoJzUjX6C8E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do the actual format conversions. **Change the input path to the one you have in your environment.**"
      ],
      "metadata": {
        "id": "wH30dfFax6oE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# change to path to your label-studio annotation JSON\n",
        "LABEL_STUDIO_ANN = Path(\"handwriting/label-studio-anno.json\")\n",
        "# change to path to your training images folder\n",
        "TRAIN_IMGS = Path(\"handwriting/training\")\n",
        "# change to path to your test images folder\n",
        "TEST_IMGS = Path(\"handwriting/test\")\n",
        "# formatted dataset for text detection will be saved in the directory below\n",
        "OUTPUT_DET_DIR = Path(\"dataset-det\")\n",
        "# formatted dataset for text recognition will be saved in the directory below\n",
        "OUTPUT_REC_DIR = Path(\"dataset-rec\")\n",
        "\n",
        "create_mmocr_det_anno(\n",
        "    LABEL_STUDIO_ANN,\n",
        "    TRAIN_IMGS,\n",
        "    TEST_IMGS,\n",
        "    OUTPUT_DET_DIR,\n",
        ")\n",
        "create_mmocr_rec_anno(\n",
        "    OUTPUT_DET_DIR,\n",
        "    OUTPUT_REC_DIR,\n",
        ")"
      ],
      "metadata": {
        "id": "uNIstUXZEV9o"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup for Training"
      ],
      "metadata": {
        "id": "FplVyX99ZjzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.13.1+cu117 \\\n",
        "  torchvision==0.14.1+cu117 \\\n",
        "  --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "!pip install -U openmim\n",
        "!mim install \"mmengine>=0.7.1,<1.1.0\"\n",
        "!mim install \"mmcv>=2.0.0rc4,<2.1.0\"\n",
        "!mim install \"mmdet>=3.0.0rc5,<3.2.0\"\n",
        "!git clone https://github.com/open-mmlab/mmocr.git\n",
        "!cd mmocr && pip install -v -e ."
      ],
      "metadata": {
        "id": "JJO1adsQEznO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d5281053-5cc6-4848-f85a-66f7ef9b19ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu117\n",
            "Collecting torch==1.13.1+cu117\n",
            "  Downloading https://download.pytorch.org/whl/cu117/torch-1.13.1%2Bcu117-cp310-cp310-linux_x86_64.whl (1801.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m658.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.14.1+cu117\n",
            "  Downloading https://download.pytorch.org/whl/cu117/torchvision-0.14.1%2Bcu117-cp310-cp310-linux_x86_64.whl (24.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1+cu117) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1+cu117) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1+cu117) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1+cu117) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1+cu117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1+cu117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1+cu117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1+cu117) (2023.11.17)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.16.0+cu121\n",
            "    Uninstalling torchvision-0.16.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.16.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 1.13.1+cu117 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.13.1+cu117 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.13.1+cu117 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.13.1+cu117 torchvision-0.14.1+cu117\n",
            "Collecting openmim\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from openmim) (8.1.7)\n",
            "Collecting colorama (from openmim)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index (from openmim)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Collecting opendatalab (from openmim)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from openmim) (1.5.3)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim) (23.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmim) (2.31.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim) (13.7.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim) (0.9.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (6.0.1)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (3.5.2)\n",
            "Collecting ordered-set (from model-index->openmim)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting pycryptodome (from opendatalab->openmim)\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim) (4.66.1)\n",
            "Collecting openxlab (from opendatalab->openmim)\n",
            "  Downloading openxlab-0.0.34-py3-none-any.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (1.23.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->openmim) (1.16.0)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting requests (from openmim)\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich (from openmim)\n",
            "  Downloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools~=60.2.0 (from openxlab->opendatalab->openmim)\n",
            "  Downloading setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm (from opendatalab->openmim)\n",
            "  Downloading tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests->openmim)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading aliyun-python-sdk-core-2.14.0.tar.gz (443 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.0/443.0 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (42.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.21)\n",
            "Building wheels for collected packages: oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112371 sha256=4ab0161914b6224eb7bcb58277bc856ebcca6626285e47695f634f7f6a469c72\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.14.0-py3-none-any.whl size=535289 sha256=c86e0158a87a8e27a178fda3f3def2668459aa65e64d190d098307ad7e015fd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/3c/68/b7eab618d9f1d5e7d386296f1e07e2cf36aaa1eb5161885038\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31406 sha256=f26481e5919b02a7172b02f4bd2b227981e5ff32915a2a306e0bdd5aee70d65b\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "Successfully built oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: crcmod, urllib3, tqdm, setuptools, pycryptodome, ordered-set, jmespath, colorama, rich, requests, model-index, aliyun-python-sdk-core, aliyun-python-sdk-kms, oss2, openxlab, opendatalab, openmim\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.7.0\n",
            "    Uninstalling rich-13.7.0:\n",
            "      Successfully uninstalled rich-13.7.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "cvxpy 1.3.3 requires setuptools>65.5.1, but you have setuptools 60.2.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.2 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.13.1+cu117 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.13.1+cu117 which is incompatible.\n",
            "yfinance 0.2.36 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aliyun-python-sdk-core-2.14.0 aliyun-python-sdk-kms-2.16.2 colorama-0.4.6 crcmod-1.7 jmespath-0.10.0 model-index-0.1.11 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.34 ordered-set-4.1.0 oss2-2.17.0 pycryptodome-3.20.0 requests-2.28.2 rich-13.4.2 setuptools-60.2.0 tqdm-4.65.2 urllib3-1.26.18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu117/torch1.13.0/index.html\n",
            "Collecting mmengine<1.1.0,>=0.7.1\n",
            "  Downloading mmengine-0.10.3-py3-none-any.whl (451 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.7/451.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from mmengine<1.1.0,>=0.7.1)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine<1.1.0,>=0.7.1) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmengine<1.1.0,>=0.7.1) (1.23.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmengine<1.1.0,>=0.7.1) (6.0.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine<1.1.0,>=0.7.1) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine<1.1.0,>=0.7.1) (2.4.0)\n",
            "Collecting yapf (from mmengine<1.1.0,>=0.7.1)\n",
            "  Downloading yapf-0.40.2-py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmengine<1.1.0,>=0.7.1) (4.8.0.76)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine<1.1.0,>=0.7.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine<1.1.0,>=0.7.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine<1.1.0,>=0.7.1) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine<1.1.0,>=0.7.1) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine<1.1.0,>=0.7.1) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine<1.1.0,>=0.7.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine<1.1.0,>=0.7.1) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine<1.1.0,>=0.7.1) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine<1.1.0,>=0.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine<1.1.0,>=0.7.1) (2.16.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine<1.1.0,>=0.7.1) (7.0.1)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine<1.1.0,>=0.7.1) (4.1.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine<1.1.0,>=0.7.1) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmengine<1.1.0,>=0.7.1) (3.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine<1.1.0,>=0.7.1) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine<1.1.0,>=0.7.1) (1.16.0)\n",
            "Installing collected packages: addict, yapf, mmengine\n",
            "Successfully installed addict-2.4.0 mmengine-0.10.3 yapf-0.40.2\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu117/torch1.13.0/index.html\n",
            "Collecting mmcv<2.1.0,>=2.0.0rc4\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu117/torch1.13.0/mmcv-2.0.1-cp310-cp310-manylinux1_x86_64.whl (73.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0rc4) (2.4.0)\n",
            "Requirement already satisfied: mmengine>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0rc4) (0.10.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0rc4) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0rc4) (23.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0rc4) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0rc4) (6.0.1)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0rc4) (0.40.2)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0rc4) (4.8.0.76)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0rc4) (3.7.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0rc4) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0rc4) (2.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.1.0,>=2.0.0rc4) (7.0.1)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.1.0,>=2.0.0rc4) (4.1.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.1.0,>=2.0.0rc4) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv<2.1.0,>=2.0.0rc4) (3.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0rc4) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0rc4) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0rc4) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0rc4) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0rc4) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0rc4) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0rc4) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0rc4) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0rc4) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv<2.1.0,>=2.0.0rc4) (1.16.0)\n",
            "Installing collected packages: mmcv\n",
            "Successfully installed mmcv-2.0.1\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu117/torch1.13.0/index.html\n",
            "Collecting mmdet<3.2.0,>=3.0.0rc5\n",
            "  Downloading mmdet-3.1.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmdet<3.2.0,>=3.0.0rc5) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmdet<3.2.0,>=3.0.0rc5) (1.23.5)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet<3.2.0,>=3.0.0rc5) (2.0.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmdet<3.2.0,>=3.0.0rc5) (1.11.4)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet<3.2.0,>=3.0.0rc5) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet<3.2.0,>=3.0.0rc5) (1.16.0)\n",
            "Collecting terminaltables (from mmdet<3.2.0,>=3.0.0rc5)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: mmcv<2.1.0,>=2.0.0rc4 in /usr/local/lib/python3.10/dist-packages (from mmdet<3.2.0,>=3.0.0rc5) (2.0.1)\n",
            "Requirement already satisfied: mmengine<1.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from mmdet<3.2.0,>=3.0.0rc5) (0.10.3)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0rc4->mmdet<3.2.0,>=3.0.0rc5) (2.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0rc4->mmdet<3.2.0,>=3.0.0rc5) (23.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0rc4->mmdet<3.2.0,>=3.0.0rc5) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0rc4->mmdet<3.2.0,>=3.0.0rc5) (6.0.1)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0rc4->mmdet<3.2.0,>=3.0.0rc5) (0.40.2)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0rc4->mmdet<3.2.0,>=3.0.0rc5) (4.8.0.76)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine<1.0.0,>=0.7.1->mmdet<3.2.0,>=3.0.0rc5) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine<1.0.0,>=0.7.1->mmdet<3.2.0,>=3.0.0rc5) (2.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet<3.2.0,>=3.0.0rc5) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet<3.2.0,>=3.0.0rc5) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet<3.2.0,>=3.0.0rc5) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet<3.2.0,>=3.0.0rc5) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet<3.2.0,>=3.0.0rc5) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet<3.2.0,>=3.0.0rc5) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine<1.0.0,>=0.7.1->mmdet<3.2.0,>=3.0.0rc5) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine<1.0.0,>=0.7.1->mmdet<3.2.0,>=3.0.0rc5) (2.16.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.1.0,>=2.0.0rc4->mmdet<3.2.0,>=3.0.0rc5) (7.0.1)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.1.0,>=2.0.0rc4->mmdet<3.2.0,>=3.0.0rc5) (4.1.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.1.0,>=2.0.0rc4->mmdet<3.2.0,>=3.0.0rc5) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv<2.1.0,>=2.0.0rc4->mmdet<3.2.0,>=3.0.0rc5) (3.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine<1.0.0,>=0.7.1->mmdet<3.2.0,>=3.0.0rc5) (0.1.2)\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "Successfully installed mmdet-3.1.0 terminaltables-3.1.10\n",
            "Cloning into 'mmocr'...\n",
            "remote: Enumerating objects: 16384, done.\u001b[K\n",
            "remote: Counting objects: 100% (293/293), done.\u001b[K\n",
            "remote: Compressing objects: 100% (220/220), done.\u001b[K\n",
            "remote: Total 16384 (delta 101), reused 200 (delta 70), pack-reused 16091\u001b[K\n",
            "Receiving objects: 100% (16384/16384), 16.24 MiB | 12.94 MiB/s, done.\n",
            "Resolving deltas: 100% (10769/10769), done.\n",
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Obtaining file:///content/mmocr\n",
            "  Running command python setup.py egg_info\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-h7ck3j6e/mmocr.egg-info\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-h7ck3j6e/mmocr.egg-info/SOURCES.txt'\n",
            "  warning: no files found matching 'mmocr/.mim/model-index.yml'\n",
            "  warning: no files found matching 'mmocr/.mim/dicts/*.txt'\n",
            "  warning: no files found matching '*.py' under directory 'mmocr/.mim/configs'\n",
            "  warning: no files found matching '*.yml' under directory 'mmocr/.mim/configs'\n",
            "  warning: no files found matching '*.sh' under directory 'mmocr/.mim/tools'\n",
            "  warning: no files found matching '*.py' under directory 'mmocr/.mim/tools'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-h7ck3j6e/mmocr.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from mmocr==1.0.1) (0.4.0)\n",
            "Collecting lmdb (from mmocr==1.0.1)\n",
            "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmocr==1.0.1) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmocr==1.0.1) (1.23.5)\n",
            "Requirement already satisfied: opencv-python!=4.5.5.*,>=4.2.0.32 in /usr/local/lib/python3.10/dist-packages (from mmocr==1.0.1) (4.8.0.76)\n",
            "Collecting pyclipper (from mmocr==1.0.1)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmocr==1.0.1) (2.0.7)\n",
            "Collecting rapidfuzz>=2.0.0 (from mmocr==1.0.1)\n",
            "  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from mmocr==1.0.1) (0.19.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug->mmocr==1.0.1) (1.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug->mmocr==1.0.1) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug->mmocr==1.0.1) (9.4.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug->mmocr==1.0.1) (2.31.6)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug->mmocr==1.0.1) (2.0.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->mmocr==1.0.1) (3.2.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->mmocr==1.0.1) (2023.12.9)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->mmocr==1.0.1) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->mmocr==1.0.1) (23.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmocr==1.0.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmocr==1.0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmocr==1.0.1) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmocr==1.0.1) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmocr==1.0.1) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmocr==1.0.1) (2.8.2)\n",
            "Installing collected packages: pyclipper, lmdb, rapidfuzz, mmocr\n",
            "  Running setup.py develop for mmocr\n",
            "    Running command python setup.py develop\n",
            "    running develop\n",
            "    /usr/local/lib/python3.10/dist-packages/setuptools/command/easy_install.py:156: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
            "      warnings.warn(\n",
            "    /usr/local/lib/python3.10/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
            "      warnings.warn(\n",
            "    running egg_info\n",
            "    creating mmocr.egg-info\n",
            "    writing manifest file 'mmocr.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'mmocr.egg-info/SOURCES.txt'\n",
            "    running build_ext\n",
            "Successfully installed lmdb-1.4.1 mmocr-1.0.1 pyclipper-1.3.0.post5 rapidfuzz-3.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Text Detection"
      ],
      "metadata": {
        "id": "qlP5KfWpFhxw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using the config file `/content/mmocr/configs/textdet/dbnet/dbnet_resnet50-dcnv2_fpnc_1200e_icdar2015.py` as the main model config. Note that each parameters can be defined in another `.py` file, since MMOCR uses distributed configuration files. Check the `_base_` of the main config.\n",
        "\n",
        "Change in the configuration:\n",
        "\n",
        "- Root data (Use ICDAR2015 config) to `dataset-det`\n",
        "- Num of iterations, try at least 50, be careful to not overfit\n",
        "- Validation cycle, try around 10 iters\n",
        "- TensorBoard visualizer\n",
        "\n",
        "  ```\n",
        "  vis_backends = [dict(type='LocalVisBackend'),\n",
        "                  dict(type='TensorboardVisBackend')]\n",
        "  ```\n",
        "\n",
        "- Only save last checkpoint\n",
        "\n",
        "  ```\n",
        "      checkpoint=dict(type='CheckpointHook', interval=10, max_keep_ckpts=1)\n",
        "  ```"
      ],
      "metadata": {
        "id": "yehNoxk0Nbqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_base_ = [\n",
        "    '/content/mmocr/configs/textdet/icdar2015_dbnet_resnet50dcnv2_fpn.py',\n",
        "    '/content/mmocr/configs/_base_/schedules/schedule_1200e.py'\n",
        "]\n",
        "\n",
        "dataset_type = 'IcdarDataset'\n",
        "data_root = 'dataset-det/'\n",
        "\n",
        "total_iters = 50\n",
        "\n",
        "evaluation = dict(interval=10)\n",
        "\n",
        "vis_backends = [\n",
        "    dict(type='LocalVisBackend'),\n",
        "    dict(type='TensorboardVisBackend')\n",
        "]\n",
        "\n",
        "checkpoint = dict(type='CheckpointHook', interval=10, max_keep_ckpts=1)\n"
      ],
      "metadata": {
        "id": "_zvSaB7jo42c"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/mmocr/tools/visualizations/browse_dataset.py \\\n",
        "  \"/content/mmocr/configs/textdet/dbnet/dbnet_resnet50_1200e_icdar2015.py\" \\\n",
        "  -o \"/content/vis\" \\\n",
        "  -m original"
      ],
      "metadata": {
        "id": "BbUFpj3yKpiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir \"/content/work_dir\""
      ],
      "metadata": {
        "id": "t2EZH1o4IH7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/mmocr/tools/train.py\" \\\n",
        "  \"/content/mmocr/configs/textdet/dbnet/dbnet_resnet50-dcnv2_fpnc_1200e_icdar2015.py\" \\\n",
        "  --work-dir \"/content/work_dir\""
      ],
      "metadata": {
        "id": "DsOxllSOJ9DW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using the config file `/content/mmocr/configs/textrecog/svtr/svtr-base_20e_st_mj.py` as the main model config. Note that each parameters can be defined in another `.py` file, since MMOCR uses distributed configuration files. Check the `_base_` of the main config.\n",
        "\n",
        "Change in the configuration:\n",
        "\n",
        "- Root data (Use ICDAR2015 config) to `dataset-rec`\n",
        "- Num of iterations, try the default fist.\n",
        "- TensorBoard visualizer\n",
        "\n",
        "  ```\n",
        "  vis_backends = [dict(type='LocalVisBackend'),\n",
        "                  dict(type='TensorboardVisBackend')]\n",
        "  ```\n",
        "\n",
        "- Only save last checkpoint\n",
        "\n",
        "  ```\n",
        "      checkpoint=dict(type='CheckpointHook', interval=1, max_keep_ckpts=1)\n",
        "  ```\n",
        "\n",
        "- Validation evaluator\n",
        "\n",
        "  ```\n",
        "  val_evaluator = dict(\n",
        "      _delete_=True,\n",
        "      type='Evaluator',\n",
        "      metrics=[\n",
        "          dict(\n",
        "              type='WordMetric',\n",
        "              mode=['exact', 'ignore_case', 'ignore_case_symbol']),\n",
        "          dict(type='CharMetric')\n",
        "      ])\n",
        "  test_evaluator = val_evaluator\n",
        "  ```\n",
        "\n",
        "- Train/test dataset list\n",
        "\n",
        "  ```\n",
        "  train_list = [_base_.icdar2015_textrecog_train]\n",
        "  test_list = [_base_.icdar2015_textrecog_test]\n",
        "  ```\n",
        "\n",
        "- Update pre-trained model\n",
        "\n",
        "  ```\n",
        "  load_from = \"https://download.openmmlab.com/mmocr/textrecog/svtr/svtr-base_20e_st_mj/svtr-base_20e_st_mj-ea500101.pth\"\n",
        "  ```\n",
        "\n",
        "- Change batch size to smaller value if you get CUDA OOM, e.g. 128"
      ],
      "metadata": {
        "id": "Qzzc5jW5x4aP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vis_backends = [\n",
        "    dict(type='LocalVisBackend'),\n",
        "    dict(type='TensorboardVisBackend')\n",
        "]\n",
        "\n",
        "# Checkpoint configuration\n",
        "checkpoint = dict(type='CheckpointHook', interval=1, max_keep_ckpts=1)\n",
        "\n",
        "# Validation Evaluator configuration\n",
        "val_evaluator = dict(\n",
        "    _delete_=True,\n",
        "    type='Evaluator',\n",
        "    metrics=[\n",
        "        dict(\n",
        "            type='WordMetric',\n",
        "            mode=['exact', 'ignore_case', 'ignore_case_symbol']),\n",
        "        dict(type='CharMetric')\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Test Evaluator configuration\n",
        "test_evaluator = val_evaluator\n",
        "\n",
        "# Train/test dataset dictionaries\n",
        "train_list = dict(\n",
        "    type='_base_.icdar2015_textrecog_train'\n",
        ")\n",
        "test_list = dict(\n",
        "    type='_base_.icdar2015_textrecog_test'\n",
        ")\n",
        "\n",
        "# Update pre-trained model\n",
        "load_from = \"https://download.openmmlab.com/mmocr/textrecog/svtr/svtr-base_20e_st_mj/svtr-base_20e_st_mj-ea500101.pth\"\n",
        "\n",
        "# Note: Change batch size to smaller value if CUDA OOM, e.g., 12\n",
        "batch_size = 16  # Replace with your desired batch size or make it configurable\n",
        "\n",
        "# Define other training parameters as needed\n",
        "\n",
        "# Placeholder for training loop or function\n",
        "def train_model():\n",
        "    # Your training code goes here\n",
        "    pass\n",
        "\n",
        "# Placeholder for testing loop or function\n",
        "def test_model():\n",
        "    # Your testing code goes here\n",
        "    pass\n",
        "\n",
        "# Run training using the defined configuration\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace with actual training and testing calls based on your framework\n",
        "    train_model()\n",
        "    test_model()"
      ],
      "metadata": {
        "id": "VmHt0nWQvqfq"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/mmocr/tools/visualizations/browse_dataset.py \\\n",
        "  \"/content/mmocr/configs/textrecog/svtr/svtr-base_20e_st_mj.py\" \\\n",
        "  -o \"/content/vis\" \\\n",
        "  -m original"
      ],
      "metadata": {
        "id": "0zYeprXQA8qA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir \"/content/work_dir\""
      ],
      "metadata": {
        "id": "Qflmo8uuz_D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/mmocr/tools/train.py\" \\\n",
        "  \"/content/mmocr/configs/textrecog/svtr/svtr-base_20e_st_mj.py\" \\\n",
        "  --work-dir \"/content/work_dir\""
      ],
      "metadata": {
        "id": "LpiqFfra0GRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.fc = nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "model = SimpleModel()\n",
        "\n",
        "# Save the model checkpoint\n",
        "checkpoint_path = \"modelOCR.pth\"\n",
        "torch.save(model.state_dict(), checkpoint_path)\n",
        "\n",
        "print(f\"Model saved to {checkpoint_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9audY5QHy4I7",
        "outputId": "56c59335-1e0a-486a-c15d-33f1340300d8"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to modelOCR.pth\n"
          ]
        }
      ]
    }
  ]
}